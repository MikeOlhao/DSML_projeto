{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc87212",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4075ae",
   "metadata": {},
   "source": [
    "# 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24debbce",
   "metadata": {},
   "source": [
    "## 1.1 Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from datetime import date\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Import a integrate data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_crm = pd.read_csv('crm.csv')\n",
    "df_mkt = pd.read_csv('mkt.csv')\n",
    "df_sales = pd.read_excel('sales.xlsx')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.merge(pd.merge(df_crm,df_sales,on='CustomerID',how=\"inner\"),df_mkt,on=\"CustomerID\",how=\"inner\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Set Index\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.set_index('CustomerID',inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 Check and removing duplicates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df.duplicated()] # checking duplicates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[~df.duplicated()] # drop duplicates rows"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Explore Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.0 Data profiling\n",
    "\n",
    "Se não quiserem instalar a biblioteca não corram esta secção. Caso contrário o comando para instalar é pip install ydata-profiling. No final **apagar esta secção**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#from ydata_profiling import ProfileReport\n",
    "#profile= ProfileReport (df, title= \"DSML_Project\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#profile.to_file('DSML_profile.html')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Basic Exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q: _To check the number of columns and rows_ we used `shape` _attribute_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> A: _The dataset has **7000 rows** and **26 columns**_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__*Q*__: Check the name of the features of the dataset we used `columns` _attribute_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> A: The dataset has the following columns/features names: <br>\n",
    "        >Index. CustomerID\n",
    "        >1. 'Name' <br>\n",
    "        >2. 'Birthyear'<br>\n",
    "        >3. 'Education'<br>\n",
    "        >4. 'Marital_Status'<br>\n",
    "        >5. 'Income'<br>\n",
    "        >6. 'Kid_Younger6'<br>\n",
    "        >7. 'Children_6to18'<br>\n",
    "        >8. 'Date_Adherence'<br>\n",
    "        >9. 'Recency'<br>\n",
    "        >10. 'MntMeat&Fish'<br>\n",
    "        >11. 'MntEntries'<br>\n",
    "        >12. 'MntVegan&Vegetarian'<br>\n",
    "        >13. 'MntDrinks'<br>\n",
    "        >14. 'MntDesserts'<br>\n",
    "        >15. 'MntAdditionalRequests'<br>\n",
    "        >16. 'NumOfferPurchases'<br>\n",
    "        >17. 'NumAppPurchases'<br>\n",
    "        >18. 'NumTakeAwayPurchases'<br>\n",
    "        >19. 'NumStorePurchases'<br>\n",
    "        >20. 'NumAppVisitsMonth'<br>\n",
    "        >21. 'Complain'<br>\n",
    "        >22. 'Response_Cmp1'<br>\n",
    "        >23. 'Response_Cmp2'<br>\n",
    "        >24. 'Response_Cmp3'<br>\n",
    "        >25. 'Response_Cmp4'<br>\n",
    "        >26. 'Response_Cmp5'<br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q: First glance of the dataset using `head` and `tail` methods to check the first and last 5 rows."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.tail(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q: To check the basic information of the dataset we've used the `info` method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    ">A: We can observe the data type of the dataset and the how many of features per data type  `dtypes: float64 - (7), int64 - (15), object - (4)`, the memory usage of `1.4+MB`, and the non-null values present per columns. <br>\n",
    "> Using only `info` method we understand that `'Education', 'Recency', 'MntDrinks'` have __14, 23, 28 null values__ that require some action."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.2 Statistical Exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2.1 Numerical Variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> _The describe return we can get a first glance and make some conclusion:_\n",
    "\n",
    ">__Birthyear__ - could originate an Age column for readability purposes<br>\n",
    "__Income__ - Min and Max are very far from each other and far from the mean value which could indicate outliers<br>\n",
    "__Recency__ - 6977 valid values, hence we should look in deep and decide on how to minimize that effect of missing values<br>\n",
    "__MntMeat&Fish__ - Min and Max are distant from each other and have high standard deviation which could effect some future conclusion<br>\n",
    "__MntEntries__ - Again has high standard deviation that we should analyze, Min and Max far apart, similar to MntMeat&Fish<br>\n",
    "__MntVegan&Vegetarian__ - Similar to the previous two Mnt columns<br>\n",
    "__MntDrinks, MntDesserts__ - Seems to be very similar between them<br>\n",
    "__MntAdditionalRequests__ - The max value standard deviation seems high and also the max value very far apart from the mean<br>\n",
    "__NumOfferPurchases, NumTakeAwayPurchases, NumAppVisitsMonth__  - Have a max value to distante from the mean that could be true but we need to take into account<br>\n",
    "__NumAppPurchases, SumStorePurchases__ - Seems does not have strange summary statistcs<br>\n",
    "__Kid_Younger6, Children_6to18__ - 75% of clients have at least one child"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Q**: Skewness of each variable "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.skew()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Concerning the variables' skewness, we can conclude the following:\n",
    "- `Moderate skewness (between |0.5| and |1.0|)`: Birthyear, Income, Kid_Younger6, Children_6to18, Recency, NumAppPurchases, NumStorePurchases, NumAppVisitsMonth\n",
    "- `High skewness (higher than |1.0|)`: MntMeat&Fish, MntEntries, MntVegan&Vegetarian, MntDrinks, MntDesserts, MntAdditionalRequests, NumOfferPurchases, NumTakeAwayPurchases, Complain, Response_Cmp1, Response_Cmp2, Response_Cmp3, Response_Cmp4, Response_Cmp5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.kurt()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Features with kurtosis higher than 3 could indicate presence of outliers, hence we should have special considerantion with the following features:\n",
    ">MntEntries, MntVegan&Vegetarian, MntDrinks, MntDesserts, NumOfferPurchases, NumAppVisitsMonth\n",
    "\n",
    "Note: Binomial Variables Complain, and Response_Cmp1 the kurtosis we will not consider as outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2.2 Categorical Values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe(include = object)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> We can conclude that the education as **14 missing** values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Level/Possible values of Categorical Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### `Name` prefix unique values and count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Name'].str.partition(\" \")[0].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the prefix we can generate a `gender` feature to further explore the dataset. We will deal with that in the data transformation capther"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **`Gender`** feature creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Gender\"] = df['Name'].str.partition(\" \")[0]\n",
    "df = df.replace({\"Gender\":{\"Mr.\": 1,\"Miss\": 0,\"Mrs.\": 0}})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### `Education` unique values and count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Education\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have some issues that will need trasformatioin:<br>\n",
    "- Graduation, Master, HighSchool are written in different ways<br>\n",
    "- `Basic` and `HighSchool` need different levels?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Education standardization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.replace({\"Education\":{\"master\":\"Master\", \"graduation\":\"Graduation\", \"phd\":\"PhD\",\"highschool\":\"HighSchool\"}})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### `Marital_Status` unique values and count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Marital_Status\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Similarly to previous feature we also have some issues that need transformation:<br>\n",
    "- Married, Together, Single, Divorced and Widow are written with lower and capital letters\n",
    "- We could also consider that Married and Together are similar and joined them in the same level<br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Marital_Status standardization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.replace({\"Marital_Status\":{\"married\":\"Married\", \"together\":\"Married\", \"single\":\"Single\",\"widow\":\"Widow\",\"divorced\":\"Divorced\",\"Together\":\"Married\"}})\n",
    "df[\"Marital_Status\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Date_Adherence` unqiue values and count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Date_Adherence\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Date_Adherence` is a date and will need transformation to a date format for further exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 Visual Exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.1 Numerical Variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4. In-Depth Exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Preprocess Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1. Data Cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.1. Outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "#ax1.boxplot(df['MntVegan&Vegetarian'])\n",
    "#ax2.boxplot(df['Income'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop(df[abs(zscore(df['MntVegan&Vegetarian'])) > 3].index, inplace=True)\n",
    "df.drop(df[abs(zscore(df['Income'])) > 3].index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "#ax1.boxplot(df['MntVegan&Vegetarian'])\n",
    "#ax2.boxplot(df['Income'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.2 Skewness Correction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['MntMeat&Fish'] = df['MntMeat&Fish'].apply(lambda x: np.log10(x+1))\n",
    "df['MntVegan&Vegetarian'] = df['MntVegan&Vegetarian'].apply(lambda x: np.log10(x+1))\n",
    "df['MntEntries'] = df['MntEntries'].apply(lambda x: np.log10(x+1))\n",
    "df['MntDrinks'] = df['MntDrinks'].apply(lambda x: np.log10(x+1))\n",
    "df['MntDesserts'] = df['MntDesserts'].apply(lambda x: np.log10(x+1))\n",
    "df['MntAdditionalRequests'] = df['MntAdditionalRequests'].apply(lambda x: np.log10(x+1))\n",
    "df['NumOfferPurchases'] = df['NumOfferPurchases'].apply(lambda x: np.log10(x+1))\n",
    "df['NumTakeAwayPurchases'] = df['NumTakeAwayPurchases'].apply(lambda x: np.log10(x+1))\n",
    "df['Complain'] = df['Complain'].apply(lambda x: np.log10(x+1))\n",
    "df['Response_Cmp1'] = df['Response_Cmp1'].apply(lambda x: np.log10(x+1))\n",
    "df['Response_Cmp2'] = df['Response_Cmp2'].apply(lambda x: np.log10(x+1))\n",
    "df['Response_Cmp3'] = df['Response_Cmp3'].apply(lambda x: np.log10(x+1))\n",
    "df['Response_Cmp4'] = df['Response_Cmp4'].apply(lambda x: np.log10(x+1))\n",
    "df['Response_Cmp5'] = df['Response_Cmp5'].apply(lambda x: np.log10(x+1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.2. Missing Values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Response_is_null = df[\"Response_Cmp1\"].isna().sum() + df[\"Response_Cmp2\"].isna().sum() + df[\"Response_Cmp3\"].isna().sum() + df[\"Response_Cmp4\"].isna().sum()\n",
    "Response_is_null == 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **`Education`**, **`Recency`**, **`MntDrinks`** and **`MntTotal`** (due to dependancy of `MntDrinks`) have missing values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Filling the missing values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fill `Education` with the mode"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Education\"].fillna(df[\"Education\"].mode()[0], inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fill `Recency` with the median value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Recency\"].fillna(df[\"Recency\"].mean(), inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#df.drop(columns = \"MntTotal\", inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mnt = df[[ 'MntMeat&Fish', 'MntEntries', 'MntVegan&Vegetarian', 'MntDrinks',\n",
    "       'MntDesserts', 'MntAdditionalRequests']]\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "array_impute = imputer.fit_transform(df_mnt)\n",
    "df_mnt = pd.DataFrame(array_impute, columns = df_mnt.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"MntDrinks\"] = df_mnt[\"MntDrinks\"].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"MntTotal\"] = df['MntMeat&Fish'] + df['MntEntries'] + df['MntVegan&Vegetarian'] + df['MntDrinks'] + df['MntDesserts']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2. Data Transformation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.1. Create new Variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utils"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating Age variable from the Birthyear"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Age'] = df.Birthyear.apply(lambda x: date.today().year-x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop('Birthyear', axis= 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating card adherence age variable from the Date adherence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "df = df.replace({\"Date_Adherence\":{\"2/29/2022\": datetime.strptime(\"2022-03-01\", '%Y-%m-%d')}}) #2022 is not a leap year, therefore 29/02/2022 is not a possible day"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['daysAsCardClient'] = df['Date_Adherence'].apply(lambda x: (date.today() - x.date()).days)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop('Date_Adherence', axis= 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fill Education"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edu_encode = pd.get_dummies(df.Education, drop_first= True)\n",
    "df = pd.concat([df, edu_encode], axis = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop('Education', axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fill Maritial Status"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "marital_encode = pd.get_dummies(df.Marital_Status, drop_first= True)\n",
    "df = pd.concat([df, marital_encode], axis = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop('Marital_Status', axis= 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create MntTotal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"MntTotal\"] = df['MntMeat&Fish'] + df['MntEntries'] + df['MntVegan&Vegetarian'] + df['MntDrinks'] + df['MntDesserts'] + df['MntAdditionalRequests']\n",
    "df[\"MntTotal\"]\n",
    "# em falta Mnt Add Requests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Mnt Pday Card"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Mnt_pday_card']= df.MntTotal/df.daysAsCardClient"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Response Campaigns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Response_Campaigns'] = df['Response_Cmp1'] + df['Response_Cmp2'] + df['Response_Cmp3'] + df['Response_Cmp4'] + df[\n",
    "       'Response_Cmp5']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# queremos dar drop nos Response, tudo certo ok? pq?\n",
    "df.drop(['Response_Cmp1', 'Response_Cmp2', 'Response_Cmp3', 'Response_Cmp4', 'Response_Cmp5'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Total Kids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Total_Kids\"] = df[\"Kid_Younger6\"] + df[\"Children_6to18\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Has Kids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"has_Kids\"] = df[\"Total_Kids\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "df[\"has_Kids\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# demos drop pq?\n",
    "df.drop(['Kid_Younger6', 'Children_6to18'], axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create age_bins"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"age_bins\"] = pd.cut(df[\"Age\"], bins = 5)\n",
    "age_bin = pd.get_dummies(df['age_bins'],prefix='age')\n",
    "df = pd.concat([df,age_bin], axis=1)\n",
    "df.drop(['age_bins'],axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Incoherencies\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[(df[['MntMeat&Fish', 'MntEntries',\n",
    "        'MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts',\n",
    "        'MntAdditionalRequests']].sum(axis = 1) > 0) & (df[['NumAppPurchases', 'NumTakeAwayPurchases', 'NumStorePurchases']].sum(axis = 1) <= 0)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# como justificar a atribuição de [0,0,0,0,0,0] às variaveis de monetary?\n",
    "\n",
    "df.loc[(df[['MntMeat&Fish', 'MntEntries',\n",
    "            'MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts',\n",
    "            'MntAdditionalRequests']].sum(axis = 1) > 0) & (df[['NumAppPurchases', 'NumTakeAwayPurchases', 'NumStorePurchases']].sum(axis = 1) <= 0),['MntMeat&Fish','MntEntries','MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts','MntAdditionalRequests']] = [0,0,0,0,0,0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[(df[['MntMeat&Fish', 'MntEntries',\n",
    "        'MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts',\n",
    "        'MntAdditionalRequests']].sum(axis = 1) > 0) & (df[['NumAppPurchases', 'NumTakeAwayPurchases', 'NumStorePurchases']].sum(axis = 1) <= 0)] # confirmação do ajuste"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[(df['NumOfferPurchases'] > df[['NumAppPurchases','NumTakeAwayPurchases','NumStorePurchases']].sum(axis=1))]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# será esta a abordagem mais acertada, isto é, assumir que todas as compras deste cliente foram \"OfferPurchases\"?\n",
    "\n",
    "df.loc[(df['NumOfferPurchases'] > df[['NumAppPurchases','NumTakeAwayPurchases','NumStorePurchases']].sum(axis=1)),'NumOfferPurchases'] = df['NumAppPurchases'] + df['NumTakeAwayPurchases'] + df['NumStorePurchases']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[(df['NumOfferPurchases'] > df[['NumAppPurchases','NumTakeAwayPurchases','NumStorePurchases']].sum(axis=1))] # confirmação do ajuste"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Review\n",
    "\n",
    "Ver a dataframe no seu estado final\n",
    "Drop: Id, name, birthyear, date_adherence, total_kids, mntTotal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train= df.copy()\n",
    "df_train.drop(['Name', 'Birthyear', 'Date_Adherence', 'Response_Cmp1', 'Response_Cmp2', 'Response_Cmp3', 'Response_Cmp4', 'Response_Cmp5',\n",
    "               'Kid_Younger6', 'Children_6to18'], axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As the problem is not a classification problem we will need to adapt our data so it can be used in classifiers. We will use Random Forest Classifiers as tools for feature selection, using MntTotal as the target variable, as our goal is to devise a marketing campaign that aims to increase sales"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x= df_train.drop(['MntTotal', 'Mnt_pday_card', 'MntAdditionalRequests', 'MntDesserts', 'MntDrinks', 'MntEntries', 'MntMeat&Fish', 'MntVegan&Vegetarian'] , axis= 1)\n",
    "y= df_train['MntTotal']\n",
    "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "y_test = np.array(y_test).reshape(-1, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scalerx = MinMaxScaler()\n",
    "scalery = MinMaxScaler()\n",
    "\n",
    "scalerx = scalerx.fit(x_train)\n",
    "scalery = scalery.fit(y_train)\n",
    "\n",
    "x_train = pd.DataFrame(scalerx.transform(x_train), columns= x.columns)\n",
    "x_test = pd.DataFrame(scalerx.transform(x_test), columns= x.columns)\n",
    "\n",
    "y_train = pd.DataFrame(scalery.transform(y_train))\n",
    "y_test = pd.DataFrame(scalery.transform(y_test))\n",
    "#df_train.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RFR = RandomForestRegressor(n_estimators=100, max_depth=5)\n",
    "RFR.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importances = pd.Series(RFR.feature_importances_, index= x_train.columns)\n",
    "importances"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "threshold = importances.median()\n",
    "selected_features = x_train.reset_index(drop=True).loc[:, importances >= threshold]\n",
    "print(selected_features.columns.to_series().reset_index(drop=True).to_string(index=False))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_RFR = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=1)\n",
    "new_RFR.fit(selected_features, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_test= x_test[selected_features.columns]\n",
    "y_pred = new_RFR.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: \", mse)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data scaling\n",
    "min max: income, recency, mnt..., purchases ..., age, daysasClient, mnt per ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_train = pd.DataFrame(scaler.fit_transform(df_train))\n",
    "#df_train.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PCA\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A implementação do pca acima pareceu me estranha. deixo aqui outra e quando reunirmos vemos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "df_train2= df_train.copy()\n",
    "pca.fit(df_train2)\n",
    "var= pca.explained_variance_ratio_\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "\n",
    "plt.title(\"PCA Variance against num of Componmnets\")\n",
    "plt.ylabel(\"Variance %\")\n",
    "plt.xlabel(\"Number of componments\")\n",
    "l = plt.axhline(80, color=\"red\")\n",
    "\n",
    "plt.plot(var1)\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca = PCA(n_components=7)\n",
    "pca_train=pca.fit_transform(df_train2)\n",
    "pca_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7 variaveis explicam ~80% da variancia"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Scores for each PC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Correlação entre PC's e as variáveis originais"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans= KMeans(n_clusters = 7, max_iter =10000, random_state= 1)\n",
    "kmeans.fit(pca_train)\n",
    "pca_train_label = kmeans.labels_\n",
    "pca_train_label = pd.DataFrame(pca_train_label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "pca_train_label.reset_index(inplace=True)\n",
    "df_final=pd.concat([df,pca_train_label],axis=1)\n",
    "df_final.set_index('CustomerID',inplace=True)\n",
    "df_final.drop(['index'],axis=1,inplace=True)\n",
    "df_final= df_final.rename(columns={0:'Cluster'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans2= KMeans(n_clusters = 7, max_iter = 10000, random_state = 1)\n",
    "kmeans2.fit(df_train)\n",
    "df_train_label = kmeans2.labels_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfTF= pd.DataFrame()\n",
    "dfTF['Compare'] = pca_train_label== df_train_label\n",
    "#pd.DataFrame(dfTF.groupby('Compare'))\n",
    "dfTF.groupby(['Compare']).size().reset_index(name='counts')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.2. Misclassifications"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.3. Incoherencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> 3.2.3.1 Clients that spent money but never had a registered Purchase"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[(df[['MntMeat&Fish', 'MntEntries',\n",
    "       'MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts',\n",
    "       'MntAdditionalRequests']].sum(axis = 1) >= 0) & (df[['NumOfferPurchases', 'NumAppPurchases',\n",
    "       'NumTakeAwayPurchases', 'NumStorePurchases']].sum(axis = 1) <= 0)].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.4. Binning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.5. Reclassification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.6. Power Transform"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3. Data Reduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3.1. Multicollinearity - Check correlation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3.2. Unary Variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3.3. Variables with a high percentage of missing values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2. Back to Data Transformation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.7. Apply ordinal encoding and create Dummy variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.8. Scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1. K-Means"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# variavel modelo visao monetary: \n",
    "        #  Mnt_pday_card, has_Kids, Income, age_bins, 'Graduation', 'HighSchool', 'Master', 'PhD', 'Gender'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_value = df[[\"Mnt_pday_card\", \"has_Kids\", \"Income\", \"Age\", 'Graduation', 'HighSchool', 'Master', 'PhD', 'Gender', \"Recency\" ]].copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ks = range(1,11)\n",
    "inertias = []\n",
    "\n",
    "\n",
    "for k in ks:\n",
    "    model = KMeans(n_clusters = k).fit(df_value)\n",
    "    inertias.append(model.inertia_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot ks (x-axis) vs inertias (y-axis) using plt.plot(). \n",
    "plt.plot(ks, inertias)\n",
    "\n",
    "# define the label for the x axis as 'number of clusters' using matplotlib.pyplot.xlabel\n",
    "plt.xlabel('number of clusters')\n",
    "# define the label for the y axis as 'inertia' using matplotlib.pyplot.ylabel\n",
    "plt.ylabel('inertia')\n",
    "# define the ticks on the x axis using the values of ks\n",
    "plt.xticks(ks)\n",
    "# call plt.show()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_value_k2 = df_value.copy()\n",
    "model_k2 = sk.cluster.KMeans(n_clusters = 2, random_state = 1).fit(df_value_k2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_value_k2[\"label\"] = model_k2.labels_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_value_k2[\"label\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_value_k2.groupby([\"label\"]).mean().transpose()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_value_k3 = df_value.copy()\n",
    "model_k3 = sk.cluster.KMeans(n_clusters = 3, random_state = 2).fit(df_value_k3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_value_k3[\"label\"] = model_k3.labels_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_value_k3[\"label\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_value_k3.groupby([\"label\"]).describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Measuring distances between clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "dists_k2 = euclidean_distances(model_k2.cluster_centers_)\n",
    "dists_k2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dists_k3 = euclidean_distances(model_k3.cluster_centers_)\n",
    "dists_k3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster0 = df_value_k2[df_value_k2.label == 0]\n",
    "cluster1 = df_value_k2[df_value_k2.label == 1]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.histplot(cluster0['Mnt_pday_card'],color='red',label='Cluster 0', bins = 20)\n",
    "sns.histplot(cluster1['Mnt_pday_card'],color='yellow',label='Cluster 1', bins = 20)\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster0 = df_value_k3[df_value_k3.label == 0]\n",
    "cluster1 = df_value_k3[df_value_k3.label == 1]\n",
    "cluster2 = df_value_k3[df_value_k3.label == 2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.histplot(cluster0['Mnt_pday_card'],color='red',label='Cluster 0', bins = 20)\n",
    "sns.histplot(cluster1['Mnt_pday_card'],color='yellow',label='Cluster 1', bins = 20)\n",
    "sns.histplot(cluster2['Mnt_pday_card'],color='green',label='Cluster 2', bins = 20)\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.histplot(cluster0['Income'],color='red',label='Cluster 0', bins = 20)\n",
    "sns.histplot(cluster1['Income'],color='yellow',label='Cluster 1', bins = 20)\n",
    "sns.histplot(cluster2['Income'],color='green',label='Cluster 2', bins = 20)\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# variavel modelo visao customer behaviour: NumOfferPurchases', 'NumAppPurchases',\n",
    "       # 'NumTakeAwayPurchases', 'NumStorePurchases', 'NumAppVisitsMonth',\n",
    "       # 'Complain', 'Gender', 'Income', 'Age', 'Graduation', 'HighSchool', 'Master', 'PhD', 'Married', 'Single',\n",
    "       # 'Widow'"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
