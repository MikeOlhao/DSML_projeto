{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc87212",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4075ae",
   "metadata": {},
   "source": [
    "# 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24debbce",
   "metadata": {},
   "source": [
    "## 1.1 Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from datetime import date\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc474e5f",
   "metadata": {},
   "source": [
    "## 1.2 Import a integrate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acdbaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crm = pd.read_csv('crm.csv')\n",
    "df_mkt = pd.read_csv('mkt.csv')\n",
    "df_sales = pd.read_excel('sales.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(pd.merge(df_crm,df_sales,on='CustomerID',how=\"inner\"),df_mkt,on=\"CustomerID\",how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3659ba1c",
   "metadata": {},
   "source": [
    "## 1.3 Set Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133e3a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('CustomerID',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1102a1",
   "metadata": {},
   "source": [
    "## 1.4 Check and removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d3e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()] # checking duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cf554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.duplicated()] # drop duplicates rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7708f19d",
   "metadata": {},
   "source": [
    "# 2. Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.0 Data profiling\n",
    "\n",
    "Se não quiserem instalar a biblioteca não corram esta secção. Caso contrário o comando para instalar é pip install ydata-profiling. No final **apagar esta secção**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from ydata_profiling import ProfileReport\n",
    "#profile= ProfileReport (df, title= \"DSML_Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#profile.to_file('DSML_profile.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f0cea9",
   "metadata": {},
   "source": [
    "## 2.1 Basic Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a938300",
   "metadata": {},
   "source": [
    "Q: _To check the number of columns and rows_ we used `shape` _attribute_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee99fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c353f14d",
   "metadata": {},
   "source": [
    "> A: _The dataset has **7000 rows** and **26 columns**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b265b69",
   "metadata": {},
   "source": [
    "__*Q*__: Check the name of the features of the dataset we used `columns` _attribute_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df65ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0613146",
   "metadata": {},
   "source": [
    "> A: The dataset has the following columns/features names: <br>\n",
    "        >Index. CustomerID\n",
    "        >1. 'Name' <br>\n",
    "        >2. 'Birthyear'<br>\n",
    "        >3. 'Education'<br>\n",
    "        >4. 'Marital_Status'<br>\n",
    "        >5. 'Income'<br>\n",
    "        >6. 'Kid_Younger6'<br>\n",
    "        >7. 'Children_6to18'<br>\n",
    "        >8. 'Date_Adherence'<br>\n",
    "        >9. 'Recency'<br>\n",
    "        >10. 'MntMeat&Fish'<br>\n",
    "        >11. 'MntEntries'<br>\n",
    "        >12. 'MntVegan&Vegetarian'<br>\n",
    "        >13. 'MntDrinks'<br>\n",
    "        >14. 'MntDesserts'<br>\n",
    "        >15. 'MntAdditionalRequests'<br>\n",
    "        >16. 'NumOfferPurchases'<br>\n",
    "        >17. 'NumAppPurchases'<br>\n",
    "        >18. 'NumTakeAwayPurchases'<br>\n",
    "        >19. 'NumStorePurchases'<br>\n",
    "        >20. 'NumAppVisitsMonth'<br>\n",
    "        >21. 'Complain'<br>\n",
    "        >22. 'Response_Cmp1'<br>\n",
    "        >23. 'Response_Cmp2'<br>\n",
    "        >24. 'Response_Cmp3'<br>\n",
    "        >25. 'Response_Cmp4'<br>\n",
    "        >26. 'Response_Cmp5'<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29734ade",
   "metadata": {},
   "source": [
    "Q: First glance of the dataset using `head` and `tail` methods to check the first and last 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf8a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf42f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced4cb06",
   "metadata": {},
   "source": [
    "Q: To check the basic information of the dataset we've used the `info` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedc7804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6794da09",
   "metadata": {},
   "source": [
    ">A: We can observe the data type of the dataset and the how many of features per data type  `dtypes: float64 - (7), int64 - (15), object - (4)`, the memory usage of `1.4+MB`, and the non-null values present per columns. <br>\n",
    "> Using only `info` method we understand that `'Education', 'Recency', 'MntDrinks'` have __14, 23, 28 null values__ that require some action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87889183",
   "metadata": {},
   "source": [
    "# 2.2 Statistical Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f7658",
   "metadata": {},
   "source": [
    "## 2.2.1 Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121f1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> _The describe return we can get a first glance and make some conclusion:_\n",
    "\n",
    ">__Birthyear__ - could originate an Age column for readability purposes<br>\n",
    "__Income__ - Min and Max are very far from each other and far from the mean value which could indicate outliers<br>\n",
    "__Recency__ - 6977 valid values, hence we should look in deep and decide on how to minimize that effect of missing values<br>\n",
    "__MntMeat&Fish__ - Min and Max are distant from each other and have high standard deviation which could effect some future conclusion<br>\n",
    "__MntEntries__ - Again has high standard deviation that we should analyze, Min and Max far apart, similar to MntMeat&Fish<br>\n",
    "__MntVegan&Vegetarian__ - Similar to the previous two Mnt columns<br>\n",
    "__MntDrinks, MntDesserts__ - Seems to be very similar between them<br>\n",
    "__MntAdditionalRequests__ - The max value standard deviation seems high and also the max value very far apart from the mean<br>\n",
    "__NumOfferPurchases, NumTakeAwayPurchases, NumAppVisitsMonth__  - Have a max value to distante from the mean that could be true but we need to take into account<br>\n",
    "__NumAppPurchases, SumStorePurchases__ - Seems does not have strange summary statistcs<br>\n",
    "__Kid_Younger6, Children_6to18__ - 75% of clients have at least one child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Q**: Skewness of each variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Concerning the variables' skewness, we can conclude the following:\n",
    "- `Moderate skewness (between |0.5| and |1.0|)`: Birthyear, Income, Kid_Younger6, Children_6to18, Recency, NumAppPurchases, NumStorePurchases, NumAppVisitsMonth\n",
    "- `High skewness (higher than |1.0|)`: MntMeat&Fish, MntEntries, MntVegan&Vegetarian, MntDrinks, MntDesserts, MntAdditionalRequests, NumOfferPurchases, NumTakeAwayPurchases, Complain, Response_Cmp1, Response_Cmp2, Response_Cmp3, Response_Cmp4, Response_Cmp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.kurt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Features with kurtosis higher than 3 could indicate presence of outliers, hence we should have special considerantion with the following features:\n",
    ">MntEntries, MntVegan&Vegetarian, MntDrinks, MntDesserts, NumOfferPurchases, NumAppVisitsMonth\n",
    "\n",
    "Note: Binomial Variables Complain, and Response_Cmp1 the kurtosis we will not consider as outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.2.2 Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe(include = object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> We can conclude that the education as **14 missing** values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Level/Possible values of Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### `Name` prefix unique values and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Name'].str.partition(\" \")[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "With the prefix we can generate a `gender` feature to further explore the dataset. We will deal with that in the data transformation capther"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **`Gender`** feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Gender\"] = df['Name'].str.partition(\" \")[0]\n",
    "df = df.replace({\"Gender\":{\"Mr.\": 1,\"Miss\": 0,\"Mrs.\": 0}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### `Education` unique values and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Education\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We have some issues that will need trasformatioin:<br>\n",
    "- Graduation, Master, HighSchool are written in different ways<br>\n",
    "- `Basic` and `HighSchool` need different levels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Education standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.replace({\"Education\":{\"master\":\"Master\", \"graduation\":\"Graduation\", \"phd\":\"PhD\",\"highschool\":\"HighSchool\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### `Marital_Status` unique values and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Marital_Status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Similarly to previous feature we also have some issues that need transformation:<br>\n",
    "- Married, Together, Single, Divorced and Widow are written with lower and capital letters\n",
    "- We could also consider that Married and Together are similar and joined them in the same level<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Marital_Status standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.replace({\"Marital_Status\":{\"married\":\"Married\", \"together\":\"Married\", \"single\":\"Single\",\"widow\":\"Widow\",\"divorced\":\"Divorced\",\"Together\":\"Married\"}})\n",
    "df[\"Marital_Status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`Date_Adherence` unqiue values and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Date_Adherence\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`Date_Adherence` is a date and will need transformation to a date format for further exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.3 Visual Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.3.1 Numerical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.4. In-Depth Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.1. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.1.1. Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- boxplot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.1.2. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Response_is_null = df[\"Response_Cmp1\"].isna().sum() + df[\"Response_Cmp2\"].isna().sum() + df[\"Response_Cmp3\"].isna().sum() + df[\"Response_Cmp4\"].isna().sum()\n",
    "Response_is_null == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- **`Education`**, **`Recency`**, **`MntDrinks`** and **`MntTotal`** (due to dependancy of `MntDrinks`) have missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Filling the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Fill `Education` with the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Education\"].fillna(df[\"Education\"].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Fill `Recency` with the median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Recency\"].fillna(df[\"Recency\"].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_mnt = df[[ 'MntMeat&Fish', 'MntEntries', 'MntVegan&Vegetarian', 'MntDrinks',\n",
    "       'MntDesserts', 'MntAdditionalRequests']]\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "array_impute = imputer.fit_transform(df_mnt)\n",
    "df_mnt = pd.DataFrame(array_impute, columns = df_mnt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"MntDrinks\"] = df_mnt[\"MntDrinks\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"MntTotal\"] = df['MntMeat&Fish'] + df['MntEntries'] + df['MntVegan&Vegetarian'] + df['MntDrinks'] + df['MntDesserts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.2. Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2.1. Create new Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Creating Age variable from the Birthyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Age'] = df.Birthyear.apply(lambda x: date.today().year-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop('Age', axis= 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "a796c176",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Creating card adherence age variable from the Date adherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "df = df.replace({\"Date_Adherence\":{\"2/29/2022\": datetime.strptime(\"2022-03-01\", '%Y-%m-%d')}}) #2022 is not a leap year, therefore 29/02/2022 is not a possible day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['daysAsCardClient'] = df['Date_Adherence'].apply(lambda x: (date.today() - x.date()).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop('Date_Adherence', axis= 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fill Education"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edu_encode = pd.get_dummies(df.Education, drop_first= True)\n",
    "df = pd.concat([df, edu_encode], axis = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop('Education', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fill Maritial Status"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "marital_encode = pd.get_dummies(df.Marital_Status, drop_first= True)\n",
    "df = pd.concat([df, marital_encode], axis = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop('Marital_Status', axis= 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create MntTotal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"MntTotal\"] = df['MntMeat&Fish'] + df['MntEntries'] + df['MntVegan&Vegetarian'] + df['MntDrinks'] + df['MntDesserts'] + df['MntAdditionalRequests']\n",
    "df[\"MntTotal\"]\n",
    "# em falta Mnt Add Requests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Mnt Pday Card"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Mnt_pday_card']= df.MntTotal/df.daysAsCardClient"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Response Campaigns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Response_Campaigns'] = df['Response_Cmp1'] + df['Response_Cmp2'] + df['Response_Cmp3'] + df['Response_Cmp4'] + df[\n",
    "       'Response_Cmp5']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop(['Response_Cmp1', 'Response_Cmp2', 'Response_Cmp3', 'Response_Cmp4', 'Response_Cmp5'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Total Kids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Total_Kids\"] = df[\"Kid_Younger6\"] + df[\"Children_6to18\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Has Kids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"has_Kids\"] = df[\"Total_Kids\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "df[\"has_Kids\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop(['Kid_Younger6', 'Children_6to18'], axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Review\n",
    "\n",
    "Ver a dataframe no seu estado final\n",
    "Drop: Id, name, birthyear, date_adherence, total_kids, mntTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train= df.copy()\n",
    "df_train.drop(['Name'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data scaling\n",
    "min max: income, recency, mnt..., purchases ..., age, daysasClient, mnt per ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_train = pd.DataFrame(scaler.fit_transform(df_train))\n",
    "#df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "A implementação do pca acima pareceu me estranha. deixo aqui outra e quando reunirmos vemos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "df_train2= df_train.copy()\n",
    "pca.fit(df_train2)\n",
    "var= pca.explained_variance_ratio_\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "\n",
    "plt.title(\"PCA Variance against num of Componmnets\")\n",
    "plt.ylabel(\"Variance %\")\n",
    "plt.xlabel(\"Number of componments\")\n",
    "l = plt.axhline(80, color=\"red\")\n",
    "\n",
    "plt.plot(var1)\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca = PCA(n_components=7)\n",
    "pca_train=pca.fit_transform(df_train2)\n",
    "pca_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7 variaveis explicam ~80% da variancia"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Loading Scores for each PC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##  Correlação entre PC's e as variáveis originais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans= KMeans(n_clusters = 100, max_iter =10000, random_state= 1)\n",
    "kmeans.fit(pca_train)\n",
    "pca_train_label = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans2= KMeans(n_clusters = 100, max_iter = 10000, random_state = 1)\n",
    "kmeans2.fit(df_train)\n",
    "df_train_label = kmeans.labels_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfTF= pd.DataFrame()\n",
    "dfTF['Compare'] = pca_train_label== df_train_label\n",
    "#pd.DataFrame(dfTF.groupby('Compare'))\n",
    "dfTF.groupby(['Compare']).size().reset_index(name='counts') #TODO perguntar sobre pca e nao pca dar modelos iguais\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "cd1fb8d0",
   "metadata": {},
   "source": [
    "### 3.2.2. Misclassifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf325433",
   "metadata": {},
   "source": [
    "### 3.2.3. Incoherencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e043eb36",
   "metadata": {},
   "source": [
    "> 3.2.3.1 Clients that spent money but never had a registered Purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[['MntMeat&Fish', 'MntEntries',\n",
    "       'MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts',\n",
    "       'MntAdditionalRequests']].sum(axis = 1) >= 0) & (df[['NumOfferPurchases', 'NumAppPurchases',\n",
    "       'NumTakeAwayPurchases', 'NumStorePurchases']].sum(axis = 1) <= 0)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70497b0",
   "metadata": {},
   "source": [
    "### 3.2.4. Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e07f7",
   "metadata": {},
   "source": [
    "### 3.2.5. Reclassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7385de6b",
   "metadata": {},
   "source": [
    "### 3.2.6. Power Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91126155",
   "metadata": {},
   "source": [
    "## 3.3. Data Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1bb4a3",
   "metadata": {},
   "source": [
    "### 3.3.1. Multicollinearity - Check correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478dd700",
   "metadata": {},
   "source": [
    "### 3.3.2. Unary Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb07fe",
   "metadata": {},
   "source": [
    "### 3.3.3. Variables with a high percentage of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20c2381",
   "metadata": {},
   "source": [
    "## 3.2. Back to Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c221ce",
   "metadata": {},
   "source": [
    "### 3.2.7. Apply ordinal encoding and create Dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee645019",
   "metadata": {},
   "source": [
    "### 3.2.8. Scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
