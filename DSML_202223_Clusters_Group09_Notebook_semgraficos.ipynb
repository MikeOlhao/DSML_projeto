{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc87212",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4075ae",
   "metadata": {},
   "source": [
    "# 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24debbce",
   "metadata": {},
   "source": [
    "## 1.1 Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fcb7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "from scipy.stats import zscore\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2197255f",
   "metadata": {},
   "source": [
    "## 1.2 Import a integrate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02275bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crm = pd.read_csv('crm.csv')\n",
    "df_mkt = pd.read_csv('mkt.csv')\n",
    "df_sales = pd.read_excel('sales.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(pd.merge(df_crm,df_sales,on='CustomerID',how=\"inner\"),df_mkt,on=\"CustomerID\",how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f8ff8",
   "metadata": {},
   "source": [
    "## 1.3 Set Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5961439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('CustomerID',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4960af6e",
   "metadata": {},
   "source": [
    "## 1.4 Check and removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c2dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()] # checking duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "31 duplicated rows, with the entire same value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.duplicated()] # drop duplicates rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef7d5e",
   "metadata": {},
   "source": [
    "# 2. Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc08fbd",
   "metadata": {},
   "source": [
    "## 2.1 Basic Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c781c4eb",
   "metadata": {},
   "source": [
    "Q: _To check the number of columns and rows_ we used `shape` _attribute_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300af697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d199c66",
   "metadata": {},
   "source": [
    "A: _The dataset has **7000 rows** and **26 columns**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c5caf",
   "metadata": {},
   "source": [
    "__*Q*__: Check the name of the features of the dataset we used `columns` _attribute_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa585afb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "089c2842",
   "metadata": {},
   "source": [
    "Q: First glance of the dataset using `head` to show 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d5d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb9190",
   "metadata": {},
   "source": [
    "Q: To check the basic information of the dataset we've used the `info` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356cfbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e0ab4f",
   "metadata": {},
   "source": [
    ">A: We can observe the data type of the dataset and the how many of features per data type  `dtypes: float64 - (7), int64 - (15), object - (4)`, the memory usage of `1.4+MB`, and the non-null values present per columns. <br>\n",
    "> Using only `info` method we understand that `'Education', 'Recency', 'MntDrinks'` have __14, 23, 28 null values__ that require some action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15364797",
   "metadata": {},
   "source": [
    "# 2.2 Statistical Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f53b0a",
   "metadata": {},
   "source": [
    "## 2.2.1 Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2863ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fad73d",
   "metadata": {},
   "source": [
    "> _The describe return we can get a first glance and make some conclusion:_\n",
    "\n",
    ">__Birthyear__ - could originate an Age column for readability purposes<br>\n",
    "__Income__ - Min and Max are very far from each other and far from the mean value which could indicate outliers<br>\n",
    "__Recency__ - 6977 valid values, hence we should look in deep and decide on how to minimize that effect of missing values<br>\n",
    "__MntMeat&Fish__ - Min and Max are distant from each other and have high standard deviation which could effect some future conclusion<br>\n",
    "__MntEntries__ - Again has high standard deviation that we should analyze, Min and Max far apart, similar to MntMeat&Fish<br>\n",
    "__MntVegan&Vegetarian__ - Similar to the previous two Mnt columns<br>\n",
    "__MntDrinks, MntDesserts__ - Seems to be very similar between them<br>\n",
    "__MntAdditionalRequests__ - The max value standard deviation seems high and also the max value very far apart from the mean<br>\n",
    "__NumOfferPurchases, NumTakeAwayPurchases, NumAppVisitsMonth__  - Have a max value to distante from the mean that could be true but we need to take into account<br>\n",
    "__NumAppPurchases, SumStorePurchases__ - Seems does not have strange summary statistcs<br>\n",
    "__Kid_Younger6, Children_6to18__ - 75% of clients have at least one child"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfea1f3b",
   "metadata": {},
   "source": [
    "**Q**: Skewness of each variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff741b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd4c9ae",
   "metadata": {},
   "source": [
    "Concerning the variables' skewness, we can conclude the following:\n",
    "- `Moderate skewness (between |0.5| and |1.0|)`: Birthyear, Income, Kid_Younger6, Children_6to18, Recency, NumAppPurchases, NumStorePurchases, NumAppVisitsMonth\n",
    "- `High skewness (higher than |1.0|)`: MntMeat&Fish, MntEntries, MntVegan&Vegetarian, MntDrinks, MntDesserts, MntAdditionalRequests, NumOfferPurchases, NumTakeAwayPurchases, Complain, Response_Cmp1, Response_Cmp2, Response_Cmp3, Response_Cmp4, Response_Cmp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11806c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.kurt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8dbe0b",
   "metadata": {},
   "source": [
    "Features with kurtosis higher than 3 could indicate presence of outliers, hence we should have special consideration with the following features:\n",
    ">MntEntries, MntVegan&Vegetarian, MntDrinks, MntDesserts, NumOfferPurchases, NumAppVisitsMonth\n",
    "\n",
    "Note: Binomial Variables Complain, and Response_Cmp1 the kurtosis we will not consider as outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ce7d8",
   "metadata": {},
   "source": [
    "## 2.2.2 Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d4196",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c46c82",
   "metadata": {},
   "source": [
    "We can conclude that the education as **14 missing** values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef3c0e0",
   "metadata": {},
   "source": [
    "#### Level/Possible values of Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1074da6c",
   "metadata": {},
   "source": [
    "### `Name` prefix unique values and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d385b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name'].str.partition(\" \")[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba48dc45",
   "metadata": {},
   "source": [
    "With the prefix we can generate a `gender` feature to further explore the dataset. We will deal with that in the data transformation capther"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fa8789",
   "metadata": {},
   "source": [
    "#### **`Gender`** feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08332d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"] = df['Name'].str.partition(\" \")[0]\n",
    "df['Male'] = df['Gender'].apply(lambda x: 1 if x == \"Mr.\" else 0)\n",
    "df['Female'] = df['Gender'].apply(lambda x: 1 if x in[\"Miss\",\"Mrs.\"] else 0)\n",
    "df.drop(\"Gender\", axis= 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "1c5672c1",
   "metadata": {},
   "source": [
    "### `Education` unique values and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797e3d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Education\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e0114",
   "metadata": {},
   "source": [
    "We have some issues that will need trasformatioin:<br>\n",
    "- Graduation, Master, HighSchool are written in different ways<br>\n",
    "- `Basic` and `HighSchool` need different levels?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed838700",
   "metadata": {},
   "source": [
    "#### Education standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab314cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({\"Education\":{\"master\":\"Master\", \"graduation\":\"Graduation\", \"phd\":\"PhD\",\"highschool\":\"HighSchool\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e672a",
   "metadata": {},
   "source": [
    "### `Marital_Status` unique values and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26232698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Marital_Status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169ae79",
   "metadata": {},
   "source": [
    "Similarly to previous feature we also have some issues that need transformation:<br>\n",
    "- Married, Together, Single, Divorced and Widow are written with lower and capital letters\n",
    "- We could also consider that Married and Together are similar and joined them in the same level<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b790cf31",
   "metadata": {},
   "source": [
    "#### Marital_Status standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({\"Marital_Status\":{\"married\":\"Married\", \"together\":\"Married\", \"single\":\"Single\",\"widow\":\"Widow\",\"divorced\":\"Divorced\",\"Together\":\"Married\"}})\n",
    "df[\"Marital_Status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf744e4",
   "metadata": {},
   "source": [
    "`Date_Adherence` unqiue values and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1419ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date_Adherence\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1decc526",
   "metadata": {},
   "source": [
    "`Date_Adherence` is a date and will need transformation to a date format for further exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ff3a6e",
   "metadata": {},
   "source": [
    "## 2.3 Visual Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d0b85",
   "metadata": {},
   "source": [
    "### 2.3.1 Numerical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6e5332",
   "metadata": {},
   "source": [
    "## 2.4. In-Depth Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3cda87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18c105a0",
   "metadata": {},
   "source": [
    "# 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c2b0da",
   "metadata": {},
   "source": [
    "### 3.1.2. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a969e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Response_is_null = df[\"Response_Cmp1\"].isna().sum() + df[\"Response_Cmp2\"].isna().sum() + df[\"Response_Cmp3\"].isna().sum() + df[\"Response_Cmp4\"].isna().sum()\n",
    "Response_is_null == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a764e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a6ddb",
   "metadata": {},
   "source": [
    "- **`Education`**, **`Recency`**, **`MntDrinks`** and **`MntTotal`** (due to dependancy of `MntDrinks`) have missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127762bd",
   "metadata": {},
   "source": [
    "#### Filling the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1223237d",
   "metadata": {},
   "source": [
    "Fill `Education` with the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df47ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Education\"].fillna(df[\"Education\"].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e970b0",
   "metadata": {},
   "source": [
    "Fill `Recency` with the median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175245de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Recency\"].fillna(df[\"Recency\"].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab17fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnt = df[[ 'MntMeat&Fish', 'MntEntries', 'MntVegan&Vegetarian', 'MntDrinks',\n",
    "       'MntDesserts', 'MntAdditionalRequests']]\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "array_impute = imputer.fit_transform(df_mnt)\n",
    "df_mnt = pd.DataFrame(array_impute, columns = df_mnt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28528fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"MntDrinks\"] = df_mnt[\"MntDrinks\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86318aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825cf358",
   "metadata": {},
   "source": [
    "## 3.2. Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8687af9",
   "metadata": {},
   "source": [
    "### 3.2.1. Create new Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb89f1f",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['NumPurchasesTotal'] = df['NumTakeAwayPurchases'] + df['NumStorePurchases'] + df['NumAppPurchases']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "ac0bbe6b",
   "metadata": {},
   "source": [
    "#### Creating Age variable from the Birthyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df.Birthyear.apply(lambda x: date.today().year-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfad1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Birthyear', axis= 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9397de3",
   "metadata": {},
   "source": [
    "#### Creating card adherence age variable from the Date adherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b3ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "df = df.replace({\"Date_Adherence\":{\"2/29/2022\": datetime.strptime(\"2022-03-01\", '%Y-%m-%d')}}) #2022 is not a leap year, therefore 29/02/2022 is not a possible day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7c337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['daysAsCardClient'] = df['Date_Adherence'].apply(lambda x: (date.today() - x.date()).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b1d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Date_Adherence', axis= 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426aced3",
   "metadata": {},
   "source": [
    "#### Fill Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af500d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_encode = pd.get_dummies(df.Education, drop_first= True) #TODO ver se nao ha formas melhores para tratar desta categoria\n",
    "df = pd.concat([df, edu_encode], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39856ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5dcbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Education', axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af23d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252d558d",
   "metadata": {},
   "source": [
    "#### Fill Maritial Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42477c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_encode = pd.get_dummies(df.Marital_Status, drop_first= True)\n",
    "df = pd.concat([df, marital_encode], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6313ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dfccc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Marital_Status', axis= 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2a1b8c",
   "metadata": {},
   "source": [
    "#### Create MntTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f831e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"MntTotal\"] = df['MntMeat&Fish'] + df['MntEntries'] + df['MntVegan&Vegetarian'] + df['MntDrinks'] + df['MntDesserts'] + df['MntAdditionalRequests']\n",
    "df[\"MntTotal\"]\n",
    "# em falta Mnt Add Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b695485",
   "metadata": {},
   "source": [
    "#### Create Mnt Pday Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa4c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Mnt_pday_card']= df.MntTotal/df.daysAsCardClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fdecef",
   "metadata": {},
   "source": [
    "#### Create Response Campaigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad97c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Response_Campaigns'] = df['Response_Cmp1'] + df['Response_Cmp2'] + df['Response_Cmp3'] + df['Response_Cmp4'] + df[\n",
    "       'Response_Cmp5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17254077",
   "metadata": {},
   "source": [
    "#### Create Total Kids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd5529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Total_Kids\"] = df[\"Kid_Younger6\"] + df[\"Children_6to18\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b63115",
   "metadata": {},
   "source": [
    "#### Create Has Kids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ea2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"has_Kids\"] = df[\"Total_Kids\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "df[\"has_Kids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaeb9e5",
   "metadata": {},
   "source": [
    "#### Create age_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age_bins\"] = pd.cut(df[\"Age\"], bins = 5)\n",
    "age_bin = pd.get_dummies(df['age_bins'],prefix='age')\n",
    "df = pd.concat([df,age_bin], axis=1)\n",
    "df.drop(['age_bins'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Ratios"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Pct_Meat&Fish'] = df['MntMeat&Fish']/df['MntTotal']\n",
    "df['Pct_Desserts'] = df['MntDesserts']/df['MntTotal']\n",
    "df['Pct_Entries'] = df['MntEntries']/df['MntTotal']\n",
    "df['Pct_Drinks'] = df['MntDrinks']/df['MntTotal']\n",
    "df['Pct_Vegan&Vegetarian'] = df['MntVegan&Vegetarian']/df['MntTotal']\n",
    "df['Pct_AdditionalRequests'] = df['MntAdditionalRequests'] /df['MntTotal']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Ratios"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Pct_Store'] = df['NumStorePurchases']/df['NumPurchasesTotal']\n",
    "df['Pct_App'] = df['NumAppPurchases']/df['NumPurchasesTotal']\n",
    "df['Pct_TakeAway'] = df['NumTakeAwayPurchases']/df['NumPurchasesTotal']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "19a28fdb",
   "metadata": {},
   "source": [
    "## Incoherencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1456373a",
   "metadata": {},
   "source": [
    "Verificar que todos os clientes que têm valores gastos têm compras registadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87616b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[['MntMeat&Fish', 'MntEntries',\n",
    "        'MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts',\n",
    "        'MntAdditionalRequests']].sum(axis = 1) > 0) & (df[['NumAppPurchases', 'NumTakeAwayPurchases', 'NumStorePurchases']].sum(axis = 1) <= 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63427484",
   "metadata": {},
   "source": [
    "Alterar as linhas que não têm compras registadas e valor gasto para que o valor gasto seja 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a360c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[(df[['MntMeat&Fish', 'MntEntries',\n",
    "                    'MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts',\n",
    "                    'MntAdditionalRequests']].sum(axis = 1) > 0) & (df[['NumAppPurchases', 'NumTakeAwayPurchases', 'NumStorePurchases']].sum(axis = 1) <= 0)].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338165b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[['MntMeat&Fish', 'MntEntries',\n",
    "        'MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts',\n",
    "        'MntAdditionalRequests']].sum(axis = 1) > 0) & (df[['NumAppPurchases', 'NumTakeAwayPurchases', 'NumStorePurchases']].sum(axis = 1) <= 0)] # confirmação do ajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19bc94c",
   "metadata": {},
   "source": [
    "Ver se não há mais compras com ofertas do que compras totais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['NumOfferPurchases'] > df[['NumAppPurchases','NumTakeAwayPurchases','NumStorePurchases']].sum(axis=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e410b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# será esta a abordagem mais acertada, isto é, assumir que todas as compras deste cliente foram \"OfferPurchases\"?\n",
    "\n",
    "df.loc[(df['NumOfferPurchases'] > df[['NumAppPurchases','NumTakeAwayPurchases','NumStorePurchases']].sum(axis=1)),'NumOfferPurchases'] = df['NumAppPurchases'] + df['NumTakeAwayPurchases'] + df['NumStorePurchases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['NumOfferPurchases'] > df[['NumAppPurchases','NumTakeAwayPurchases','NumStorePurchases']].sum(axis=1))] # confirmação do ajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e915211",
   "metadata": {},
   "source": [
    "### 3.1.2 Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06783478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "#ax1.boxplot(df['MntVegan&Vegetarian'])\n",
    "#ax2.boxplot(df['Income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650005e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[abs(zscore(df['MntVegan&Vegetarian'])) > 3].index,\n",
    "        inplace=True)\n",
    "df.drop(df[abs(zscore(df['Income'])) > 3].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4fa281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "#ax1.boxplot(df['MntVegan&Vegetarian'])\n",
    "#ax2.boxplot(df['Income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415f2353",
   "metadata": {},
   "source": [
    "# 3.1.1 Skewness Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d6e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Ver se o sklearn nao tem funçao para fazer isto. ver sklearn.preprocessing, meter depois de outliers/incoherencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MntMeat&Fish'] = df['MntMeat&Fish'].apply(lambda x: np.log10(x+1))\n",
    "df['MntVegan&Vegetarian'] = df['MntVegan&Vegetarian'].apply(lambda x: np.log10(x+1))\n",
    "df['MntEntries'] = df['MntEntries'].apply(lambda x: np.log10(x+1))\n",
    "df['MntDrinks'] = df['MntDrinks'].apply(lambda x: np.log10(x+1))\n",
    "df['MntDesserts'] = df['MntDesserts'].apply(lambda x: np.log10(x+1))\n",
    "df['MntAdditionalRequests'] = df['MntAdditionalRequests'].apply(lambda x: np.log10(x+1))\n",
    "df['NumOfferPurchases'] = df['NumOfferPurchases'].apply(lambda x: np.log10(x+1))\n",
    "df['NumTakeAwayPurchases'] = df['NumTakeAwayPurchases'].apply(lambda x: np.log10(x+1))\n",
    "df['Complain'] = df['Complain'].apply(lambda x: np.log10(x+1))\n",
    "df['Response_Cmp1'] = df['Response_Cmp1'].apply(lambda x: np.log10(x+1))\n",
    "df['Response_Cmp2'] = df['Response_Cmp2'].apply(lambda x: np.log10(x+1))\n",
    "df['Response_Cmp3'] = df['Response_Cmp3'].apply(lambda x: np.log10(x+1))\n",
    "df['Response_Cmp4'] = df['Response_Cmp4'].apply(lambda x: np.log10(x+1))\n",
    "df['Response_Cmp5'] = df['Response_Cmp5'].apply(lambda x: np.log10(x+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f591d015",
   "metadata": {},
   "source": [
    "## Data Review\n",
    "\n",
    "Ver a dataframe no seu estado final\n",
    "Drop: Id, name, birthyear, date_adherence, total_kids, mntTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5004ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61a82d",
   "metadata": {},
   "source": [
    "Utilizar df como base para treinos/clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc442746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Name'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270548b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "37c2cf1e",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e962b48",
   "metadata": {},
   "source": [
    "As the problem is not a classification problem we will need to adapt our data so it can be used in classifiers. We will use Random Forest Classifiers as tools for feature selection, using MntTotal as the target variable, as our goal is to devise a marketing campaign that aims to increase sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fdf170",
   "metadata": {},
   "source": [
    "## Redução de Dimensões e Scaling\n",
    "Pipeline para passar da df para uma df que se possa utilizar nos modelos de clustering.\n",
    "1: Selecionar as colunas a partir da dataframe df. Criar uma copia com as colunas desejadas utilizando a função df_select\n",
    "2: Aplicar a função scaling_dfs que aplica scaling à dataframe obtida no passo anterior e retorna uma df scaled\n",
    "3: Escolher o método de redução de dimensoes a aplicar: PCA ou Feature selection com RandomForest\n",
    "3.1.1 PCA: Utilizar a função PCA_graph_df para ver quantos principal components serão necessários para a variancia desejada\n",
    "3.1.2 PCA: Utilizar a função create_PCA_df para aplicar PCA com o numero de componentes desejado à dataframe obtida em 2, obtendo uma df com o numero de colunas igual ao numero de principal components\n",
    "3.2.1 Feature Selection com RandomForest: Utilizar a função RFR_feature_select para obter os nomes das colunas consideradas importantes e o MSE (para ver se a abordagem é viável). Atenção que a df utilizada para fazer feature selection deverá ser uma com as colunas desejadas mas **SEM SCALING**, para que não haja bleeding de informação.\n",
    "3.2.2 Feature Selection com RandomForest: Utilizar a função selected_features_df para obter uma df sem scaling com apenas as colunas obtidas no passo anterior mais a coluna da target variable. **Aplicar o passo 2 apenas agora**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b0dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_select(column_names: list, df: pd.DataFrame):\n",
    "    df_train = df[column_names].copy()\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b446af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_dfs(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    df_total_scaled = pd.DataFrame(scaler.fit_transform(df))\n",
    "    return df_total_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef8954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_graph_df(df_scaled: pd.DataFrame, exp_variance: int):\n",
    "    pca = PCA()\n",
    "    pca.fit(df_scaled)\n",
    "    var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "\n",
    "    plt.title(\"PCA Variance against num of Componmnets\")\n",
    "    plt.ylabel(\"Variance %\")\n",
    "    plt.xlabel(\"Number of componments\")\n",
    "    l = plt.axhline(exp_variance, color=\"red\")\n",
    "\n",
    "    plt.plot(var1)\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a358f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_PCA_df(n_components: int, df_scaled: pd.DataFrame):\n",
    "    pca = PCA(n_components= n_components)\n",
    "    pca_train=pca.fit_transform(df_scaled)\n",
    "    return pca_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadf8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFR_feature_select(df: pd.DataFrame, target_var: str):\n",
    "\n",
    "    x = df.drop([target_var], axis= 1).copy()\n",
    "    y = df[target_var].copy()\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    y_train = np.array(y_train).reshape(-1, 1)\n",
    "    y_test = np.array(y_test).reshape(-1, 1)\n",
    "\n",
    "    scalerx = MinMaxScaler()\n",
    "    scalery = MinMaxScaler()\n",
    "\n",
    "    scalerx = scalerx.fit(x_train)\n",
    "    scalery = scalery.fit(y_train)\n",
    "\n",
    "    x_train = pd.DataFrame(scalerx.transform(x_train), columns= x.columns)\n",
    "    x_test = pd.DataFrame(scalerx.transform(x_test), columns= x.columns)\n",
    "\n",
    "    y_train = pd.DataFrame(scalery.transform(y_train))\n",
    "    y_test = pd.DataFrame(scalery.transform(y_test))\n",
    "\n",
    "    RFR = RandomForestRegressor(random_state= 1)\n",
    "    RFR.fit(x_train, y_train)\n",
    "\n",
    "    importances = pd.Series(RFR.feature_importances_, index= x_train.columns)\n",
    "    threshold = importances.median()\n",
    "    selected_features = x_train.reset_index(drop=True).loc[:, importances >= threshold]\n",
    "\n",
    "    new_RFR = RandomForestRegressor(random_state=1)\n",
    "    new_RFR.fit(selected_features, y_train)\n",
    "\n",
    "    x_test= x_test[selected_features.columns]\n",
    "    y_pred = new_RFR.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return list(selected_features.columns), mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ddd87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selected_features_df(selected_columns: list, target_variable: str, df: pd.DataFrame):\n",
    "    selected_columns = selected_columns.append(target_variable)\n",
    "    selected_df = df[selected_columns].copy()\n",
    "    return selected_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ccf5b",
   "metadata": {},
   "source": [
    "## Exemplo\n",
    "\n",
    "Neste exemplo serão utilizadas as colunas que vimos na quarta com o método PCA e o modelo kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5835c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_columns = ['Income', 'Recency', 'NumOfferPurchases', 'NumAppPurchases',\n",
    "       'NumTakeAwayPurchases', 'NumStorePurchases', 'NumAppVisitsMonth',\n",
    "       'Complain', 'Gender', 'daysAsCardClient',\n",
    "       'Graduation', 'HighSchool', 'Master', 'PhD', 'Married', 'Single',\n",
    "       'Widow', 'MntTotal', 'Response_Campaigns',\n",
    "       'Total_Kids', 'age_(17.943, 29.4]', 'age_(29.4, 40.8]',\n",
    "       'age_(40.8, 52.2]', 'age_(52.2, 63.6]', 'age_(63.6, 75.0]']\n",
    "kmeans_df = df_select(column_names= kmeans_columns, df= df) #Step 1\n",
    "kmeans_df_scaled = scaling_dfs(kmeans_df) #Step 2\n",
    "PCA_graph_df(df_scaled= kmeans_df_scaled, exp_variance= 80) #Step 3.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7057f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pca_df= create_PCA_df(n_components= 7, df_scaled= kmeans_df_scaled) #Step 3.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0e0b0c",
   "metadata": {},
   "source": [
    "## Treino de modelos e avaliação\n",
    "Pipeline para passar de uma dataframe com dimensoes reduzidas para modelos de clustering e as suas métricas **Só funciona para modelos semelhantes a kmeans** #TODO fazer para modelos com outra estrutura\n",
    "\n",
    "1: Criação do modelo. Utilizar os modelos do sklearn.cluster para obter um objeto **model** que se possa utilizar nas funções\n",
    "2: Escolha do número de clusters utilizando uma das funções ..._nclusters\n",
    "2.1 Elbow Method: Queremos selecionar o número de clusters que corresponde ao ponto da curva em que a derivada começa a ter declives menores\n",
    "2.2 Total Sum of Squares Method: Queremos selecionar o número de clusters que maximiza o between_ss e minimza o within_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow_nclusters(model_type, dimensioned_df: pd.DataFrame, cluster_range: int):\n",
    "    ks = range(1,cluster_range)\n",
    "    inertias = []\n",
    "\n",
    "\n",
    "    for k in ks:\n",
    "        model = model_type(n_clusters = k).fit(dimensioned_df)\n",
    "        inertias.append(model.inertia_)\n",
    "    # Plot ks (x-axis) vs inertias (y-axis) using plt.plot().\n",
    "    plt.plot(ks, inertias)\n",
    "\n",
    "    # define the label for the x axis as 'number of clusters' using matplotlib.pyplot.xlabel\n",
    "    plt.xlabel('number of clusters')\n",
    "    # define the label for the y axis as 'inertia' using matplotlib.pyplot.ylabel\n",
    "    plt.ylabel('inertia')\n",
    "    # define the ticks on the x axis using the values of ks\n",
    "    plt.xticks(ks)\n",
    "    # call plt.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5c1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumsquares_nclusters(model_type,  dimensioned_df: pd.DataFrame, cluster_range: int):\n",
    "    within_ss = []\n",
    "    between_ss = []\n",
    "    model_list = []\n",
    "    n_cluster = range(1,cluster_range)\n",
    "\n",
    "    ssc = pd.DataFrame({\"model\": n_cluster})\n",
    "    ssc_melted = pd.melt(ssc, id_vars=[\"model\"], var_name=\"measurement\", value_name=\"value\")\n",
    "\n",
    "    for k in n_cluster:\n",
    "        model = model_type(n_clusters=k)\n",
    "        model.fit(dimensioned_df)\n",
    "        within_ss.append(model.inertia_)\n",
    "        between_ss.append(sum(np.min(\n",
    "            cdist(dimensioned_df, model.cluster_centers_, 'euclidean'), axis=1)) / dimensioned_df.shape[0])\n",
    "        model_list.append(model)\n",
    "\n",
    "        ssc.loc[ssc[\"model\"] == k, \"within_ss\"] = within_ss[-1]\n",
    "        ssc.loc[ssc[\"model\"] == k, \"between_ss\"] = between_ss[-1]\n",
    "\n",
    "    ssc_melted = pd.melt(ssc, id_vars=[\"model\"], var_name=\"measurement\", value_name=\"value\")\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(x=\"model\", y=np.log10(ssc_melted[\"value\"]),\n",
    "                hue=\"measurement\", data=ssc_melted)\n",
    "    plt.title(\"Cluster Model Comparison\")\n",
    "    plt.xlabel(\"Number of Clusters\")\n",
    "    plt.ylabel(\"Log10 Total Sum of Squares\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abd4ea9",
   "metadata": {},
   "source": [
    "## 4. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8c6159",
   "metadata": {},
   "source": [
    "## Model Train\n",
    "\n",
    "Modelos utilizados: kmeans\n",
    "Modelos propostos: DBScan, Kmodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57059ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans= KMeans(n_clusters = 4, max_iter =10000, random_state= 1)\n",
    "kmeans.fit(kmeans_pca_df)\n",
    "pca_train_label = kmeans.labels_\n",
    "pca_train_label = pd.DataFrame(pca_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65951745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = kmeans.predict(kmeans_pca_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d4675d",
   "metadata": {},
   "source": [
    "# variavel modelo visao monetary:\n",
    " Mnt_pday_card, has_Kids, Income, age_bins, 'Graduation', 'HighSchool', 'Master', 'PhD', 'Gender'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1721b2d",
   "metadata": {},
   "source": [
    "### Measuring distances between clusters\n",
    "\n",
    "#TODO Experimentar com 3 clusters para ver se as distancias aumentam/diminuem para fundamentar a escolha do numero de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc7fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "dists = euclidean_distances(kmeans.cluster_centers_)\n",
    "dists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e27e111",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea039636",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster0 = df[df.cluster == 0]\n",
    "cluster1 = df[df.cluster == 1]\n",
    "cluster2 = df[df.cluster == 2]\n",
    "cluster3 = df[df.cluster == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a13cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(cluster0['Income'],color='red',label='Cluster 0', bins = 20)\n",
    "sns.histplot(cluster1['Income'],color='yellow',label='Cluster 1', bins = 20)\n",
    "sns.histplot(cluster2['Income'],color='green',label='Cluster 2', bins = 20)\n",
    "sns.histplot(cluster3['Income'],color='blue',label='Cluster 3', bins = 20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91dd704",
   "metadata": {},
   "source": [
    "# variavel modelo visao customer behaviour: NumOfferPurchases', 'NumAppPurchases',\n",
    "       'NumTakeAwayPurchases', 'NumStorePurchases', 'NumAppVisitsMonth',\n",
    "       'Complain', 'Gender', 'Income', 'Age', 'Graduation', 'HighSchool', 'Master', 'PhD', 'Married', 'Single',\n",
    "       'Widow'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4def6a67",
   "metadata": {},
   "source": [
    "## Murilo - Análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#num_cols = ['Income', 'MntMeat&Fish', 'MntEntries', 'MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts', 'MntAdditionalRequests']\n",
    "#cat_cols = ['age_(17.943, 29.4]', 'age_(29.4, 40.8]', 'age_(40.8, 52.2]', 'age_(52.2, 63.6]', 'age_(63.6, 75.0]', 'Graduation', 'HighSchool', 'Master', 'PhD', 'Married', 'Single', 'Widow']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_cols = ['Income', 'Recency', 'MntMeat&Fish', 'MntEntries',\n",
    "            'MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts',\n",
    "            'MntAdditionalRequests', 'NumOfferPurchases', 'NumAppPurchases',\n",
    "            'NumTakeAwayPurchases', 'NumStorePurchases', 'NumAppVisitsMonth', 'Complain', 'daysAsCardClient']\n",
    "cat_cols = ['Married', 'Single', 'Widow',\n",
    "            'NumPurchasesTotal', 'Response_Campaigns', 'Kid_Younger6',\n",
    "            'age_(17.943, 29.4]', 'age_(29.4, 40.8]', 'age_(40.8, 52.2]', 'age_(52.2, 63.6]', 'age_(63.6, 75.0]']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f2d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "kprototype_columns = []\n",
    "kprototype_columns.extend(num_cols)\n",
    "kprototype_columns.extend(cat_cols)\n",
    "\n",
    "kprototype_df = df_select(column_names= kprototype_columns, df= df)\n",
    "\n",
    "df_num = kprototype_df[num_cols]\n",
    "df_cat = kprototype_df[cat_cols]\n",
    "\n",
    "df_num = df_num.reset_index(drop=True)\n",
    "df_cat = df_cat.reset_index(drop=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_num_scaled = scaler.fit_transform(df_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8861a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_graph_df(df_scaled= df_num_scaled, exp_variance= 80) #Step 3.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59812265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o PCA às colunas numéricas\n",
    "pca = PCA(n_components=4)\n",
    "df_num_pca = pca.fit_transform(df_num_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sem o PCA às colunas numéricas\n",
    "#df_num_pca = df_num_scaled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "300a380c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Concatenando as colunas numéricas do PCA com as colunas categóricas\n",
    "df_combined = pd.concat([pd.DataFrame(df_num_pca), df_cat], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_elbow(X, k_range):\n",
    "    costs = []\n",
    "    for k in k_range:\n",
    "        print(k)\n",
    "        kp = KPrototypes(n_clusters=k, init='Huang', n_init=20, verbose=0, n_jobs=4, random_state=1)\n",
    "        kp.fit(X, categorical=[i for i in range(4, len(X.columns))])\n",
    "        costs.append(kp.cost_)\n",
    "    plt.plot(k_range, costs, marker='o')\n",
    "    plt.xticks(k_range)\n",
    "    plt.xlabel('Número de clusters (k)')\n",
    "    plt.ylabel('Cost')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot_elbow(df_combined, range(1, 11))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_combined.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9d8f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o K-Prototypes\n",
    "kp = KPrototypes(n_clusters=4, init='Huang', n_init=20, verbose=0, n_jobs=4, random_state=1)\n",
    "clusters_kp = kp.fit_predict(df_combined, categorical=[i for i in range(4, len(df_combined.columns))])\n",
    "\n",
    "# Adicionando os clusters ao DataFrame original\n",
    "df['Cluster_kp'] = clusters_kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4660edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kprototype_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da848fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster0 = df[df.Cluster_kp == 0]\n",
    "cluster1 = df[df.Cluster_kp == 1]\n",
    "cluster2 = df[df.Cluster_kp == 2]\n",
    "cluster3 = df[df.Cluster_kp == 3]\n",
    "\n",
    "\n",
    "sns.histplot(cluster0['Income'], color='red', label='Cluster 0', bins=20)\n",
    "sns.histplot(cluster1['Income'], color='yellow', label='Cluster 1', bins=20)\n",
    "sns.histplot(cluster2['Income'], color='green', label='Cluster 2', bins=20)\n",
    "sns.histplot(cluster3['Income'], color='orange', label='Cluster 3', bins=20)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dists = euclidean_distances(kp.cluster_centroids_)\n",
    "dists"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_df= df.groupby('Cluster_kp').agg({'Income': 'mean', 'Kid_Younger6': 'mean', 'Children_6to18': 'mean', 'Complain': 'sum', 'NumPurchasesTotal': 'mean', 'Age': 'mean',\n",
    "                                         'Male': 'sum', 'Female': 'sum', 'daysAsCardClient': 'mean', 'Graduation': 'sum' , 'HighSchool': 'sum', 'Master': 'sum',\n",
    "                                         'PhD': 'sum', 'Married': 'sum', 'Single': 'sum','Widow': 'sum', 'MntTotal': 'mean', 'Response_Campaigns': 'mean','Total_Kids': 'mean',\n",
    "                                         'Pct_Meat&Fish': 'mean', 'Pct_Desserts': 'mean', 'Pct_Entries': 'mean', 'Pct_Drinks': 'mean', 'Pct_Vegan&Vegetarian': 'mean',\n",
    "                                         'Pct_AdditionalRequests': 'mean', 'Pct_Drinks': 'mean', 'Pct_Vegan&Vegetarian': 'mean', 'Pct_Store': 'mean', 'Pct_App': 'mean',\n",
    "                                         'Pct_TakeAway': 'mean'\n",
    "                                         })"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "column_names = {\n",
    "    'Income': 'Income (mean)',\n",
    "    'Kid_Younger6': 'Kid_Younger6 (mean)',\n",
    "    'Children_6to18': 'Children_6to18 (mean)',\n",
    "    'Complain': 'Complain (sum)',\n",
    "    'NumPurchasesTotal': 'NumPurchasesTotal (mean)',\n",
    "    'Age': 'Age (mean)',\n",
    "    'Male': 'Male (sum)',\n",
    "    'Female': 'Female (sum)',\n",
    "    'daysAsCardClient': 'daysAsCardClient (mean)',\n",
    "    'Graduation': 'Graduation (sum)',\n",
    "    'HighSchool': 'HighSchool (sum)',\n",
    "    'Master': 'Master (sum)',\n",
    "    'PhD': 'PhD (sum)',\n",
    "    'Married': 'Married (sum)',\n",
    "    'Single': 'Single (sum)',\n",
    "    'Widow': 'Widow (sum)',\n",
    "    'MntTotal': 'MntTotal (mean)',\n",
    "    'Response_Campaigns': 'Response_Campaigns (mean)',\n",
    "    'Total_Kids': 'Total_Kids (mean)',\n",
    "    'Pct_Meat&Fish': 'Pct_Meat&Fish (mean)',\n",
    "    'Pct_Desserts': 'Pct_Desserts (mean)',\n",
    "    'Pct_Entries': 'Pct_Entries (mean)',\n",
    "    'Pct_Drinks': 'Pct_Drinks (mean)',\n",
    "    'Pct_Vegan&Vegetarian': 'Pct_Vegan&Vegetarian (mean)',\n",
    "    'Pct_AdditionalRequests': 'Pct_AdditionalRequests (mean)',\n",
    "    'Pct_Store': 'Pct_Store (mean)',\n",
    "    'Pct_App': 'Pct_App (mean)',\n",
    "    'Pct_TakeAway': 'Pct_TakeAway (mean)',\n",
    "    'Cluster_kp': 'Cluster_kp'\n",
    "}\n",
    "\n",
    "# rename the columns using the dictionary\n",
    "output_df = output_df.rename(columns=column_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 3)\n",
    "output_df=output_df.transpose().round(3).to_csv('output_df.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas.plotting import parallel_coordinates\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Call parallel_coordinates with the new figure and the desired columns\n",
    "parallel_coordinates(df[['MntEntries', 'MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts',\n",
    "       'MntAdditionalRequests', 'Cluster_kp']], 'Cluster_kp', color=('red', 'blue', 'yellow', 'green'))\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title('Parallel Coordinates Plot')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas.plotting import parallel_coordinates\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Call parallel_coordinates with the new figure and the desired columns\n",
    "parallel_coordinates(df[['NumOfferPurchases', 'NumAppPurchases',\n",
    "            'NumTakeAwayPurchases', 'NumStorePurchases', 'Cluster_kp']], 'Cluster_kp', color=('red', 'blue', 'yellow', 'green'))\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title('Parallel Coordinates Plot')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas.plotting import parallel_coordinates\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Call parallel_coordinates with the new figure and the desired columns\n",
    "parallel_coordinates(df[['Pct_Meat&Fish', 'Pct_Desserts', 'Pct_Entries',\n",
    "       'Pct_Drinks', 'Pct_Vegan&Vegetarian', 'Pct_AdditionalRequests', 'Cluster_kp']], 'Cluster_kp', color=('red', 'blue', 'yellow'))\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title('Parallel Coordinates Plot')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas.plotting import parallel_coordinates\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Call parallel_coordinates with the new figure and the desired columns\n",
    "parallel_coordinates(df[[ 'Pct_Store', 'Pct_App', 'Pct_TakeAway', 'Cluster_kp']], 'Cluster_kp', color=('red', 'blue', 'yellow'))\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title('Parallel Coordinates Plot')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
