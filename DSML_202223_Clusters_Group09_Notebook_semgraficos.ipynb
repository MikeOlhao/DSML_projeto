{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc87212",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4075ae",
   "metadata": {},
   "source": [
    "# 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24debbce",
   "metadata": {},
   "source": [
    "## 1.1 Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "from scipy.stats import zscore\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Import a integrate data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_crm = pd.read_csv('crm.csv')\n",
    "df_mkt = pd.read_csv('mkt.csv')\n",
    "df_sales = pd.read_excel('sales.xlsx')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.merge(pd.merge(df_crm,df_sales,on='CustomerID',how=\"inner\"),df_mkt,on=\"CustomerID\",how=\"inner\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Set Index\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.set_index('CustomerID',inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 Check and removing duplicates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df.duplicated()] # checking duplicates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[~df.duplicated()] # drop duplicates rows"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Explore Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.0 Data profiling\n",
    "\n",
    "Se não quiserem instalar a biblioteca não corram esta secção. Caso contrário o comando para instalar é pip install ydata-profiling. No final **apagar esta secção**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#from ydata_profiling import ProfileReport\n",
    "#profile= ProfileReport (df, title= \"DSML_Project\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#profile.to_file('DSML_profile.html')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Basic Exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q: _To check the number of columns and rows_ we used `shape` _attribute_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> A: _The dataset has **7000 rows** and **26 columns**_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__*Q*__: Check the name of the features of the dataset we used `columns` _attribute_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> A: The dataset has the following columns/features names: <br>\n",
    "        >Index. CustomerID\n",
    "        >1. 'Name' <br>\n",
    "        >2. 'Birthyear'<br>\n",
    "        >3. 'Education'<br>\n",
    "        >4. 'Marital_Status'<br>\n",
    "        >5. 'Income'<br>\n",
    "        >6. 'Kid_Younger6'<br>\n",
    "        >7. 'Children_6to18'<br>\n",
    "        >8. 'Date_Adherence'<br>\n",
    "        >9. 'Recency'<br>\n",
    "        >10. 'MntMeat&Fish'<br>\n",
    "        >11. 'MntEntries'<br>\n",
    "        >12. 'MntVegan&Vegetarian'<br>\n",
    "        >13. 'MntDrinks'<br>\n",
    "        >14. 'MntDesserts'<br>\n",
    "        >15. 'MntAdditionalRequests'<br>\n",
    "        >16. 'NumOfferPurchases'<br>\n",
    "        >17. 'NumAppPurchases'<br>\n",
    "        >18. 'NumTakeAwayPurchases'<br>\n",
    "        >19. 'NumStorePurchases'<br>\n",
    "        >20. 'NumAppVisitsMonth'<br>\n",
    "        >21. 'Complain'<br>\n",
    "        >22. 'Response_Cmp1'<br>\n",
    "        >23. 'Response_Cmp2'<br>\n",
    "        >24. 'Response_Cmp3'<br>\n",
    "        >25. 'Response_Cmp4'<br>\n",
    "        >26. 'Response_Cmp5'<br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q: First glance of the dataset using `head` and `tail` methods to check the first and last 5 rows."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.tail(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q: To check the basic information of the dataset we've used the `info` method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    ">A: We can observe the data type of the dataset and the how many of features per data type  `dtypes: float64 - (7), int64 - (15), object - (4)`, the memory usage of `1.4+MB`, and the non-null values present per columns. <br>\n",
    "> Using only `info` method we understand that `'Education', 'Recency', 'MntDrinks'` have __14, 23, 28 null values__ that require some action."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.2 Statistical Exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2.1 Numerical Variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> _The describe return we can get a first glance and make some conclusion:_\n",
    "\n",
    ">__Birthyear__ - could originate an Age column for readability purposes<br>\n",
    "__Income__ - Min and Max are very far from each other and far from the mean value which could indicate outliers<br>\n",
    "__Recency__ - 6977 valid values, hence we should look in deep and decide on how to minimize that effect of missing values<br>\n",
    "__MntMeat&Fish__ - Min and Max are distant from each other and have high standard deviation which could effect some future conclusion<br>\n",
    "__MntEntries__ - Again has high standard deviation that we should analyze, Min and Max far apart, similar to MntMeat&Fish<br>\n",
    "__MntVegan&Vegetarian__ - Similar to the previous two Mnt columns<br>\n",
    "__MntDrinks, MntDesserts__ - Seems to be very similar between them<br>\n",
    "__MntAdditionalRequests__ - The max value standard deviation seems high and also the max value very far apart from the mean<br>\n",
    "__NumOfferPurchases, NumTakeAwayPurchases, NumAppVisitsMonth__  - Have a max value to distante from the mean that could be true but we need to take into account<br>\n",
    "__NumAppPurchases, SumStorePurchases__ - Seems does not have strange summary statistcs<br>\n",
    "__Kid_Younger6, Children_6to18__ - 75% of clients have at least one child"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Q**: Skewness of each variable "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.skew()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Concerning the variables' skewness, we can conclude the following:\n",
    "- `Moderate skewness (between |0.5| and |1.0|)`: Birthyear, Income, Kid_Younger6, Children_6to18, Recency, NumAppPurchases, NumStorePurchases, NumAppVisitsMonth\n",
    "- `High skewness (higher than |1.0|)`: MntMeat&Fish, MntEntries, MntVegan&Vegetarian, MntDrinks, MntDesserts, MntAdditionalRequests, NumOfferPurchases, NumTakeAwayPurchases, Complain, Response_Cmp1, Response_Cmp2, Response_Cmp3, Response_Cmp4, Response_Cmp5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.kurt()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Features with kurtosis higher than 3 could indicate presence of outliers, hence we should have special considerantion with the following features:\n",
    ">MntEntries, MntVegan&Vegetarian, MntDrinks, MntDesserts, NumOfferPurchases, NumAppVisitsMonth\n",
    "\n",
    "Note: Binomial Variables Complain, and Response_Cmp1 the kurtosis we will not consider as outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2.2 Categorical Values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe(include = object)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> We can conclude that the education as **14 missing** values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Level/Possible values of Categorical Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### `Name` prefix unique values and count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Name'].str.partition(\" \")[0].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the prefix we can generate a `gender` feature to further explore the dataset. We will deal with that in the data transformation capther"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **`Gender`** feature creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Gender\"] = df['Name'].str.partition(\" \")[0]\n",
    "df = df.replace({\"Gender\":{\"Mr.\": 1,\"Miss\": 0,\"Mrs.\": 0}})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### `Education` unique values and count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Education\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have some issues that will need trasformatioin:<br>\n",
    "- Graduation, Master, HighSchool are written in different ways<br>\n",
    "- `Basic` and `HighSchool` need different levels?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Education standardization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.replace({\"Education\":{\"master\":\"Master\", \"graduation\":\"Graduation\", \"phd\":\"PhD\",\"highschool\":\"HighSchool\"}})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### `Marital_Status` unique values and count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Marital_Status\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Similarly to previous feature we also have some issues that need transformation:<br>\n",
    "- Married, Together, Single, Divorced and Widow are written with lower and capital letters\n",
    "- We could also consider that Married and Together are similar and joined them in the same level<br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Marital_Status standardization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.replace({\"Marital_Status\":{\"married\":\"Married\", \"together\":\"Married\", \"single\":\"Single\",\"widow\":\"Widow\",\"divorced\":\"Divorced\",\"Together\":\"Married\"}})\n",
    "df[\"Marital_Status\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Date_Adherence` unqiue values and count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Date_Adherence\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Date_Adherence` is a date and will need transformation to a date format for further exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 Visual Exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.1 Numerical Variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4. In-Depth Exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Preprocess Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1. Data Cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.1. Outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "#ax1.boxplot(df['MntVegan&Vegetarian'])\n",
    "#ax2.boxplot(df['Income'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop(df[abs(zscore(df['MntVegan&Vegetarian'])) > 3].index, inplace=True) #TODO verificar condiçoes de filtraçao de outliers, meter depois das incoherencies\n",
    "df.drop(df[abs(zscore(df['Income'])) > 3].index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "#ax1.boxplot(df['MntVegan&Vegetarian'])\n",
    "#ax2.boxplot(df['Income'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.2 Skewness Correction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df['MntMeat&Fish'] = df['MntMeat&Fish'].apply(lambda x: np.log10(x+1))\n",
    "# df['MntVegan&Vegetarian'] = df['MntVegan&Vegetarian'].apply(lambda x: np.log10(x+1))\n",
    "# df['MntEntries'] = df['MntEntries'].apply(lambda x: np.log10(x+1))\n",
    "# df['MntDrinks'] = df['MntDrinks'].apply(lambda x: np.log10(x+1)) #TODO Ver se o sklearn nao tem funçao para fazer isto. ver sklearn.preprocessing, meter depois de outliers/incoherencies\n",
    "# df['MntDesserts'] = df['MntDesserts'].apply(lambda x: np.log10(x+1))\n",
    "# df['MntAdditionalRequests'] = df['MntAdditionalRequests'].apply(lambda x: np.log10(x+1))\n",
    "# df['NumOfferPurchases'] = df['NumOfferPurchases'].apply(lambda x: np.log10(x+1))\n",
    "# df['NumTakeAwayPurchases'] = df['NumTakeAwayPurchases'].apply(lambda x: np.log10(x+1))\n",
    "# df['Complain'] = df['Complain'].apply(lambda x: np.log10(x+1))\n",
    "# df['Response_Cmp1'] = df['Response_Cmp1'].apply(lambda x: np.log10(x+1))\n",
    "# df['Response_Cmp2'] = df['Response_Cmp2'].apply(lambda x: np.log10(x+1))\n",
    "# df['Response_Cmp3'] = df['Response_Cmp3'].apply(lambda x: np.log10(x+1))\n",
    "# df['Response_Cmp4'] = df['Response_Cmp4'].apply(lambda x: np.log10(x+1))\n",
    "# df['Response_Cmp5'] = df['Response_Cmp5'].apply(lambda x: np.log10(x+1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.1.2. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Response_is_null = df[\"Response_Cmp1\"].isna().sum() + df[\"Response_Cmp2\"].isna().sum() + df[\"Response_Cmp3\"].isna().sum() + df[\"Response_Cmp4\"].isna().sum()\n",
    "Response_is_null == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- **`Education`**, **`Recency`**, **`MntDrinks`** and **`MntTotal`** (due to dependancy of `MntDrinks`) have missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Filling the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Fill `Education` with the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Education\"].fillna(df[\"Education\"].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Fill `Recency` with the median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Recency\"].fillna(df[\"Recency\"].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mnt = df[[ 'MntMeat&Fish', 'MntEntries', 'MntVegan&Vegetarian', 'MntDrinks',\n",
    "       'MntDesserts', 'MntAdditionalRequests']]\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "array_impute = imputer.fit_transform(df_mnt)\n",
    "df_mnt = pd.DataFrame(array_impute, columns = df_mnt.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"MntDrinks\"] = df_mnt[\"MntDrinks\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.2. Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2.1. Create new Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Creating Age variable from the Birthyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Age'] = df.Birthyear.apply(lambda x: date.today().year-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop('Birthyear', axis= 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating card adherence age variable from the Date adherence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "df = df.replace({\"Date_Adherence\":{\"2/29/2022\": datetime.strptime(\"2022-03-01\", '%Y-%m-%d')}}) #2022 is not a leap year, therefore 29/02/2022 is not a possible day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['daysAsCardClient'] = df['Date_Adherence'].apply(lambda x: (date.today() - x.date()).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop('Date_Adherence', axis= 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fill Education"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edu_encode = pd.get_dummies(df.Education, drop_first= True) #TODO ver se nao ha formas melhores para tratar desta categoria\n",
    "df = pd.concat([df, edu_encode], axis = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop('Education', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fill Maritial Status"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "marital_encode = pd.get_dummies(df.Marital_Status, drop_first= True)\n",
    "df = pd.concat([df, marital_encode], axis = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop('Marital_Status', axis= 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create MntTotal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"MntTotal\"] = df['MntMeat&Fish'] + df['MntEntries'] + df['MntVegan&Vegetarian'] + df['MntDrinks'] + df['MntDesserts'] + df['MntAdditionalRequests']\n",
    "df[\"MntTotal\"]\n",
    "# em falta Mnt Add Requests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Mnt Pday Card"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Mnt_pday_card']= df.MntTotal/df.daysAsCardClient"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Response Campaigns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Response_Campaigns'] = df['Response_Cmp1'] + df['Response_Cmp2'] + df['Response_Cmp3'] + df['Response_Cmp4'] + df[\n",
    "       'Response_Cmp5']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Total Kids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Total_Kids\"] = df[\"Kid_Younger6\"] + df[\"Children_6to18\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Has Kids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"has_Kids\"] = df[\"Total_Kids\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "df[\"has_Kids\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create age_bins"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"age_bins\"] = pd.cut(df[\"Age\"], bins = 5)\n",
    "age_bin = pd.get_dummies(df['age_bins'],prefix='age')\n",
    "df = pd.concat([df,age_bin], axis=1)\n",
    "df.drop(['age_bins'],axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Incoherencies\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verificar que todos os clientes que têm valores gastos têm compras registadas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[(df[['MntMeat&Fish', 'MntEntries',\n",
    "        'MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts',\n",
    "        'MntAdditionalRequests']].sum(axis = 1) > 0) & (df[['NumAppPurchases', 'NumTakeAwayPurchases', 'NumStorePurchases']].sum(axis = 1) <= 0)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alterar as linhas que não têm compras registadas e valor gasto para que o valor gasto seja 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# como justificar a atribuição de [0,0,0,0,0,0] às variaveis de monetary?\n",
    "\n",
    "df.loc[(df[['MntMeat&Fish', 'MntEntries',\n",
    "            'MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts',\n",
    "            'MntAdditionalRequests']].sum(axis = 1) > 0) & (df[['NumAppPurchases', 'NumTakeAwayPurchases', 'NumStorePurchases']].sum(axis = 1) <= 0),['MntMeat&Fish','MntEntries','MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts','MntAdditionalRequests']] = [0,0,0,0,0,0] #TODO dar drop das linhas que não têm a condição acima"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[(df[['MntMeat&Fish', 'MntEntries',\n",
    "        'MntVegan&Vegetarian', 'MntDrinks', 'MntDesserts',\n",
    "        'MntAdditionalRequests']].sum(axis = 1) > 0) & (df[['NumAppPurchases', 'NumTakeAwayPurchases', 'NumStorePurchases']].sum(axis = 1) <= 0)] # confirmação do ajuste"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ver se não há mais compras com ofertas do que compras totais"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[(df['NumOfferPurchases'] > df[['NumAppPurchases','NumTakeAwayPurchases','NumStorePurchases']].sum(axis=1))]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# será esta a abordagem mais acertada, isto é, assumir que todas as compras deste cliente foram \"OfferPurchases\"?\n",
    "\n",
    "df.loc[(df['NumOfferPurchases'] > df[['NumAppPurchases','NumTakeAwayPurchases','NumStorePurchases']].sum(axis=1)),'NumOfferPurchases'] = df['NumAppPurchases'] + df['NumTakeAwayPurchases'] + df['NumStorePurchases']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[(df['NumOfferPurchases'] > df[['NumAppPurchases','NumTakeAwayPurchases','NumStorePurchases']].sum(axis=1))] # confirmação do ajuste"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Review\n",
    "\n",
    "Ver a dataframe no seu estado final\n",
    "Drop: Id, name, birthyear, date_adherence, total_kids, mntTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizar df como base para treinos/clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(['Name'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As the problem is not a classification problem we will need to adapt our data so it can be used in classifiers. We will use Random Forest Classifiers as tools for feature selection, using MntTotal as the target variable, as our goal is to devise a marketing campaign that aims to increase sales"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x= df.drop(['MntTotal', 'Mnt_pday_card', 'MntAdditionalRequests', 'MntDesserts', 'MntDrinks', 'MntEntries', 'MntMeat&Fish', 'MntVegan&Vegetarian'] , axis= 1)\n",
    "y= df['MntTotal']\n",
    "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "y_test = np.array(y_test).reshape(-1, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scalerx = MinMaxScaler()\n",
    "scalery = MinMaxScaler()\n",
    "\n",
    "scalerx = scalerx.fit(x_train)\n",
    "scalery = scalery.fit(y_train)\n",
    "\n",
    "x_train = pd.DataFrame(scalerx.transform(x_train), columns= x.columns)\n",
    "x_test = pd.DataFrame(scalerx.transform(x_test), columns= x.columns)\n",
    "\n",
    "y_train = pd.DataFrame(scalery.transform(y_train))\n",
    "y_test = pd.DataFrame(scalery.transform(y_test))\n",
    "#df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RFR = RandomForestRegressor(n_estimators=100, max_depth=5, random_state= 1)\n",
    "RFR.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importances = pd.Series(RFR.feature_importances_, index= x_train.columns)\n",
    "importances"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "threshold = importances.median()\n",
    "selected_features = x_train.reset_index(drop=True).loc[:, importances >= threshold]\n",
    "print(selected_features.columns.to_series().reset_index(drop=True).to_string(index=False))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_RFR = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=1)\n",
    "new_RFR.fit(selected_features, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_test= x_test[selected_features.columns]\n",
    "y_pred = new_RFR.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: \", mse)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data scaling\n",
    "min max: income, recency, mnt..., purchases ..., age, daysasClient, mnt per ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_total_scaled = pd.DataFrame(scaler.fit_transform(df))\n",
    "#df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "A implementação do pca acima pareceu me estranha. deixo aqui outra e quando reunirmos vemos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(df_total_scaled)\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "\n",
    "plt.title(\"PCA Variance against num of Componmnets\")\n",
    "plt.ylabel(\"Variance %\")\n",
    "plt.xlabel(\"Number of componments\")\n",
    "l = plt.axhline(80, color=\"red\")\n",
    "\n",
    "plt.plot(var1)\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca_train=pca.fit_transform(df_total_scaled)\n",
    "pca_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Elbow Method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ks = range(1,11)\n",
    "inertias = []\n",
    "\n",
    "\n",
    "for k in ks: #TODO Meter isto antes do kmeans\n",
    "    model = KMeans(n_clusters = k).fit(df_total_scaled)\n",
    "    inertias.append(model.inertia_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot ks (x-axis) vs inertias (y-axis) using plt.plot().\n",
    "plt.plot(ks, inertias)\n",
    "\n",
    "# define the label for the x axis as 'number of clusters' using matplotlib.pyplot.xlabel\n",
    "plt.xlabel('number of clusters')\n",
    "# define the label for the y axis as 'inertia' using matplotlib.pyplot.ylabel\n",
    "plt.ylabel('inertia')\n",
    "# define the ticks on the x axis using the values of ks\n",
    "plt.xticks(ks)\n",
    "# call plt.show()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans= KMeans(n_clusters = 4, max_iter =10000, random_state= 1)\n",
    "kmeans.fit(pca_train)\n",
    "pca_train_label = kmeans.labels_\n",
    "pca_train_label = pd.DataFrame(pca_train_label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['cluster'] = kmeans.predict(pca_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# variavel modelo visao monetary:\n",
    " Mnt_pday_card, has_Kids, Income, age_bins, 'Graduation', 'HighSchool', 'Master', 'PhD', 'Gender'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Measuring distances between clusters\n",
    "\n",
    "#TODO Experimentar com 3 clusters para ver se as distancias aumentam/diminuem para fundamentar a escolha do numero de clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "dists = euclidean_distances(kmeans.cluster_centers_)\n",
    "dists"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster0 = df[df.cluster == 0]\n",
    "cluster1 = df[df.cluster == 1]\n",
    "cluster2 = df[df.cluster == 2]\n",
    "cluster3 = df[df.cluster == 3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.histplot(cluster0['Income'],color='red',label='Cluster 0', bins = 20)\n",
    "sns.histplot(cluster1['Income'],color='yellow',label='Cluster 1', bins = 20)\n",
    "sns.histplot(cluster2['Income'],color='green',label='Cluster 2', bins = 20)\n",
    "sns.histplot(cluster3['Income'],color='blue',label='Cluster 3', bins = 20)\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# variavel modelo visao customer behaviour: NumOfferPurchases', 'NumAppPurchases',\n",
    "       'NumTakeAwayPurchases', 'NumStorePurchases', 'NumAppVisitsMonth',\n",
    "       'Complain', 'Gender', 'Income', 'Age', 'Graduation', 'HighSchool', 'Master', 'PhD', 'Married', 'Single',\n",
    "       'Widow'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
